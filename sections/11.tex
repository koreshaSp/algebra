\section{Лекция 16.04}
\subsection{Асимптотическая оценка координат произвольной матрицы}
\begin{motivation}
    На прошлой лекции получили очень мощное утверждение, про существование Жордановой формы
    для любой матрицы, причём единственной с точность до перестановки блоков.
\end{motivation}
$A \in M_n(\mathbb{C})$ Хотим понять как ведёт себя последовательность элементов
$A^k v_0 = v_k$, а именно как она себя ведёт при $k \to \infty$. Заметим, что
в ситуации, когда оператор $A$ диагонализуем, ответ мы уже 
\hyperref[stm:Ассимптотика диагонализуемого оператора]{знаем}. Пользуясь, тем что 
\hyperref[thm:О жордановом базисе]{всегда существует Жорданов базис}, получаем 
$\exists f\colon [A]^f_f = J \Leftrightarrow \exists C\colon A = C J C^{-1}$, где
$e$~--- стандартный базис, $f$~--- Жорданов базис, а
$C = [id]^f_e $ это матрица перехода из стандартного базиса в Жорданов. Тогда просто
по \hyperref[def:Матрица отображения]{определению} координат оператора, матрицу $C$ можно выразить следующим образом:
$C = \big( [f_1]_e, \dots, [f_n]_e \big)$. Про матрицу $C^{-1}$ тоже всё понятно, она
просто равна $[id]^e_f$ по одному из 
\hyperref[stm:О свойстве матриц линейных отображений]{свойств} матрицы линейного отображения.
Тогда $A^k v_0 = C J^k C^{-1} v_0$, значит можно просто понять как ведёт себя $J^k$ при
$k \to \infty$, поведение $C, C^{-1}$ нас не особо интересует, так как они не зависят от
$k$ и их можно воспринимать как константные множители.

Давайте научимся возводить $J$ в большую степень, благо это не сложно благодаря её 
специальному виду. В первую очередь заметим, что мы можем разбить матрицу $J$ на
Жордановы блоки, возвести в степень их, после чего слепить из них матрицу $J^k$.
Посмотрим как ведёт себя Жорданов блок при возведении в степень.
\[
    \begin{gathered}
        J_m(\lambda)^k = 
        \begin{pNiceMatrix}
             \lambda & 1 & 0 & \Cdots & 0\\
             0 & \Ddots & \Ddots & \Ddots & \Vdots\\
             \Vdotsfor{2}&\Ddots& & & 0\\
             & & & & 1\\
             0 & \Hdotsfor{2} & 0 & \lambda\\
         \end{pNiceMatrix}^k = 
         (\lambda E + N)^k 
         =\lambda^k E +  \lambda^{k - 1} \binom{k}{1} N + \dots + \lambda^{k - i} \binom{k}{i} N^i + \dots + N^k
    \end{gathered}
\] 
В последнем переходе мы воспользовались формулой бинома Ньютона, так как произведение матриц
$N, E$ является коммутативным. Теперь, глядя на эту сумму заметим, что нам интересны
только первые $m - 1$ слагаемых, так как
$N^m = 0$(\hyperref[fix:nilpotent]{уже доказывали}). Нетрудно показать, что $N^i$ это матрица
на $i$ побочной диагонали стоят единички, а во всех остальных элементах нули. Доказывается очевидно,
(см картинку).

\[
    N = \begin{pNiceMatrix}[nullify-dots]
         0 & 1 & & & & \Block{2-1}<\LARGE>{0}\\
         & \Ddots & \Ddots\\
         \\\\
         \Block{1-2}<\LARGE>{0} & & & & & 1\\
                                & & & & & 0\\
     \end{pNiceMatrix}
     \quad
     N^2 = \begin{pNiceMatrix}[nullify-dots]
         0 & 0 & 1 & & & \Block{2-1}<\LARGE>{0}\\
         & \Ddots & \Ddots & \Ddots \\
         \\
         & & & & & 1\\
         \Block{1-2}<\LARGE>{0} & & & & & 0\\
                                & & & & & 0\\
     \end{pNiceMatrix}
     \quad
     N^3 = \begin{pNiceMatrix}[nullify-dots]
         0 & 0 & 0 & 1 & & \Block{1-1}<\LARGE>{0}\\
         & \Ddots & \Ddots & \Ddots & \Ddots \\
         & & & & & 1\\
         & & & & & 0\\
         \Block{1-2}<\LARGE>{0} & & & & & 0\\
                                & & & & & 0\\
     \end{pNiceMatrix} \quad N^4 = \dots
\] 
Тогда уже можно увидеть чему равна написанная ранее сумма:
\[
    J_m(\lambda)^k = (\lambda E + N)^k =
    \begin{pNiceMatrix}[nullify-dots]
        \lambda^k & \binom{k}{1}\lambda^{k-1} & \binom{k}{2}\lambda^{k-2} & & & \binom{k}{m-1}\lambda^{k-m-1}\\
         & \Ddots & \Ddots & \Ddots \\
         \\
         & & & & & \binom{k}{2}\lambda^{k-2}\\
        \Block{1-2}<\LARGE>{0} & & & & & \binom{k}{1}\lambda^{k-1}\\
                               & & & & & \lambda^k\\
     \end{pNiceMatrix}
\]
Откуда видно, что все коэффициенты этой клетки это $\mathcal{O}(k^{m-1} \lambda^k)$, 
при условии если оценить $\binom{k}{m - 1} = \mathcal{O}(k^{m-1})$. 
Эта оценку можно так же переписать следующим образом: 
$\mathcal{O}((\lambda + \epsilon)^{k}), \forall \epsilon$ сонаправленного с $\lambda$.
Эта оценка будет весьма полезна нам, когда мы будем искать максимальное по
модулю собственное число и собственный вектор матрицы.

\begin{statement}
    $A \in M_n(\mathbb{C})$ у матрицы $A$ есть собственное число $\lambda$, которое
    не кратное и максимальное по модулю. Тогда $v = c_1 f_1 + \dots + c_n f_n$, где
    $f$ это Жорданов базис, а $f_1$~--- собственный вектор для $\lambda$. Тогда
    $A^k v = c_1 \lambda^k f_1 + o(\lambda^k)$. Эту запись следует понимать как:
    коэффициенты при других базисных векторах есть $o(\lambda_k)$.
\end{statement}
\begin{proof}
    Для того, чтобы найти коэффициенты в Жордановом базисе сперва логично перейти в него. 
    Тогда вместо матрицы $A$ возникает её Жорданова форма $J$, а вместо вектора $v$ возникает
    столбец его координат в Жордановом базисе, тогда исходное равенство в новых координатах
    записывается следующим образом: 
    $J^k \begin{psmallmatrix} c_1\\\vdots\\c_n \end{psmallmatrix}$. Распишем $J^k$ и 
    воспользуемся тем, что $\lambda$ не кратное и максимальное по модулю. То, что оно
    не кратное означает, что в $J$ есть только одна Жорданова клетка с числом $\lambda$
    и её размер равен $1$ все элементы этой клетки после возведения в степень
    можно оценить как $\mathcal{O}(\lambda^k)$. То, что происходит в других Жордановых клетках нас не
    особо интересует, так как по рассуждению ранее в этом разделе можно понять, что это
    оценивается как $o(\lambda^k)$.
    Тогда наше произведение матриц можно записать в следующем виде:
    \[
     J^k \begin{pmatrix} c_1\\\vdots\\c_n \end{pmatrix} 
     =
     \begin{pNiceMatrix}
            \Block[borders={bottom,right}]{1-1}{\lambda^k} & & & \Block{2-1}<\LARGE>{0}\\
            & \Block[borders={bottom,right,top, left}]{1-1}{o(\lambda^k)} \\
            \Block{2-1}<\LARGE>{0} & & \Ddots\\
            & & & \Block[borders={top, left}]{1-1}{o(\lambda^k)} \\
     \end{pNiceMatrix}
     \begin{pmatrix} c_1\\\vdots\\c_n \end{pmatrix} = 
     \begin{pmatrix}
         \lambda^k c_1\\
         o(\lambda^k)\\
         \vdots\\
         o(\lambda^k)\\
     \end{pmatrix}
    \] 
    Таким образом, получили чего и хотели(при переходе в исходный базис).
\end{proof}
\subsection{Приближённое решение системы линейных уравнений}
Теперь подумаем в каких ранее возникших задачах помогает наше рассуждение.
Оказывается, что при помощи нашего утверждения, можно очень быстро находить приближённое
решение СЛУ.

\begin{statement}
    Пусть мы хотим решить систему уравнений: $x = Ax + b \Leftrightarrow (E - A)x = b$.
    Если все собственные числа $A$ меньше единицы по модулю, то из этого следует, что последовательность
    $x_{i + 1} = Ax_i + b$, а $x_0$ было взято случайно, то последовательность $x_i$ 
    будет сходиться к единственному решению СЛУ.
\end{statement}
\begin{proof}
    Докажем, что у системы есть единственное решение. Если для произвольного $x$ система выполняется,
    то это равносильно тому, что $(E - A)$ является обратимой.
\end{proof}
