\section{Лекция 16.04}
\subsection{Жорданова клетка}
\begin{motivation}
    В прошлый раз мы пользовались тем, что алгебраическая кратность равна геометрической. Хотим понять в каких случаях это условие
    выполняется. Спойлер: не везде выполнено, но если расширить пространство до алгебраического замыкания(например $\R$ заменить на $\C$),
    то это условие будет выполнено всегда.
\end{motivation}
\begin{example}
    Пример, когда алгебраическая кратность не равна геометрической.
     \[
         A = 
         \begin{pmatrix}
             0 & 1\\
             0 & 0
         \end{pmatrix}
    .\] 
    $\chi_A(t) = t^2$, причём 
    $\ker A - 0 E = \ker A = \langle \begin{psmallmatrix} 1\\0 \end{psmallmatrix}\rangle$
    видно, что в этой ситуации не может быть базиса из собственных векторов.
\end{example}
\begin{motivation}
    Хотим понять и формализовать все препятствия, которые возникают при диагонализации 
    матриц.
\end{motivation}
\begin{definition}
    \label{def:жорданова клетка}
    $A$~--- Жорданова клетка размера $k$ для собственного числа $\lambda$, если
     \[
         A = 
         \begin{pNiceMatrix}
             \lambda & 1 & 0 & \Cdots & 0\\
             0 & \Ddots & \Ddots & \Ddots & \Vdots\\
             \Vdotsfor{2}&\Ddots& & & 0\\
                 & & & & 1\\
             0 & \Hdotsfor{2} & 0 & \lambda\\
         \end{pNiceMatrix} \in M_k
    .\] 
    Будем в дальнейшем обозначать её как $J_k(\lambda)$
\end{definition}
\begin{remark}
    Заметим, что $\chi_A(t) = (-1)^k(t-\lambda)^k= (\lambda-t)^k$,  $\dim \ker(A - \lambda E) = 1$
\end{remark}
\begin{remark}
    Матрицы такого вида показывают нам, что существуют матрицы, для которых алгебраическая
    кратность является произвольным числом, но геометрическая кратность при этом 1.
\end{remark}
\subsection{Инвариантные подпространства}
\begin{definition}
    $U\le V$ будем называть инвариантным относительно оператора $A$ если $A(U) \subseteq U$.
\end{definition}
\begin{remark}
    Если $v$~--- собственный вектор для $A$, то $\langle v \rangle$~--- инвариантное подпространство.
    $\dim U = 1$ и $U$~--- инвариантное, тогда $U = \langle v\rangle$, где  $v$~--- собственный для $A$.
    Поэтому инвариантные подпространства можно воспринимать как некоторое 
    обобщение собственного вектора.
\end{remark}
\begin{examples}
    \begin{enumerate}
        \item
            $\ker A$~--- инвариантное относительно $A$.
        \item
             $\im A$~--- инвариантное относительно $A$.
         \item
             $p(x)\in K[x]$, Договоримся, что в этот многочлен можно подставлять и матрицу
             следующим образом: $p(A) = a_0 + a_1 A + a_2 A^2 + \dots a_n A^n$.
             Заметим, что в этом случае есть очень удобное свойство:
             $(p(x)q(x))|_{x = A} = p(A)q(A)$. Тогда можно доказать, что $\ker p(A)$ является
             инвариантным подпространством относительно оператора $A$. Действительно, нам необходимо
             проверить, что $Ax \in \ker p(A) \Leftrightarrow p(A)(Ax) = 0$, если известно, что $p(A)x = 0$.
             Заметим, что матрица коммутирует с многочленом от неё же,
             то есть $p(A)(Ax) = (p(A)A)x = A\underbrace{p(A)x}_{=0} = 0$, что и требовалось
             доказать.
     \end{enumerate}
\end{examples}
\begin{remark}
    Поймём пользу которую нам может принести найденное инвариантное подпространство.
    Пусть $\langle v_1,\dots, v_k\rangle = U$ инвариантно относительно $A$. 
    Если \hyperref[thm:О дополнении до базиса]{дополнить этот набор до базиса}, получим 
    $v_1,\dots, v_k, v_{k + 1},\dots v_n$~--- базис $V$.
    Если каждый столбец $i$ соответствует вектору $v_i$, то получаем следующий вид матрицы $A$
    в базисе $v$.
    \[
        [A]^v_v = 
        \left(\begin{array}{c|c}
                A|_U & *\\
                \hline
                0 & A|_{V/U}
        \end{array}\right)
    .\] 
    Нули стоят в левой нижней части, так как мы знаем, что $A v_i \in U, \forall i\in \overline{1,k}$,
    а значит такие вектора выражаются через $v_1,\dots,v_k$.
    Что такое $V/U$ мы не обсуждали, но нам это не очень понадобится, поэтому можно считать, что в правой нижней части стоит что
    угодно. 
    
    Важно отметить то, что правая верхняя часть не влияет на характеристический многочлен.
    А это значит, что при помощи этого факта можно считать характеристический многочлен методом
    разделяй и властвуй, при условии что мы быстро умеем находить инвариантные подпространства
    размерности примерно $1/2$ от исходной.
\end{remark}
\begin{remark}
    В специфическом случае
    $V = U_1 \oplus U_2$. Прямая сумма инвариантных подпространств. Прошлое замечание приобретает вид:
     \[
         \left(\begin{array}{c|c}
                 A|_{U_1} & 0\\
                 \hline
                 0 & A|_{U_2}
         \end{array}\right)
    .\] 
\end{remark}
\begin{remark}
    Будем считать, что далее мы работаем над алгебраически замкнутым полем $K$.
\end{remark}
\begin{theorem}[О аннулирующем операторе]
    $A$~--- оператор на пространстве $V$ над полем $K$. $p(x), q(x) \in K[x]$~--- многочлены, для которых выполнено: 
     \begin{enumerate}
         \item $pq(A) = 0$ (свойство называется аннуляция оператора).
         \item $(p, q) = 1$ (многочлены взаимно простые).
    \end{enumerate}
    Тогда в этом случае $V = \ker p(A) \oplus \ker q(A)$.
\end{theorem}
\begin{proof}
    То, что $(p,q) = 1$ значит, что 
    $h(x)p(x) + g(x)q(x) = 1$(так как существует линейное разложение их НОД).
    А из этого можно получить следующее тождество, если переписать это на языке операторов:
    $h(A)p(A) + g(A) q(A) = E$, где $E$ является тождественным оператором, и равенство
    стоит между двумя операторами.
    Тогда можно подействовать этими эквивалентными операторами на вектор $v$, получить
    следующее равенство: $h(A)(p(A)v) + g(A)(q(A)v) = v$.

    Докажем, что $p(A)v\in \ker q(A)$ следует из $pq(A) = 0$.
    \[
        p(A)v\in \ker q(A) \Leftrightarrow q(A)(p(A)v) = 0 \Leftrightarrow (pq)(A)v = 0 \Leftarrow pq(A)=0
    \] 
    
    Получили, что $p(A)v\in \ker q(A), q(A)v\in \ker p(A)$ так как $pq(A)=0$,
    тогда в равенстве выше вектор $v$ разложился на сумму векторов из $\ker q(A), \ker p(A)$:
    \[
        v = 
        \overbrace{h(A)(\underbrace{p(A)v}_{\in \ker q(A)})}^{\in \ker q(A)} + 
        \overbrace{g(A)(\underbrace{q(A)v}_{\in \ker p(A)})}^{\in \ker p(A)}
    .\]
    Тут мы неявно
    воспользовались тем, что ядро многочлена оператора инвариантно оператору, а
    значит и многочлену от оператора.

    Теперь давайте докажем, что такое разложение $v$ единственно, для этого достаточно
    показать, что $\ker p(A) \cap \ker q(A) = 0$. Возьмём произвольный
    $x\in \ker p(A)\cap \ker q(A)$. Хотим показать, что $x = 0$.
    Из того, где лежит  $x$ следует, что $p(A)x = 0 = q(A)x$.
    Тогда в равенстве $h(A)(p(A)x) + g(A)(q(A)x) = x$ с обоих сторон находятся нули, 
    значит $x = 0$.
\end{proof}
\begin{follow}
    Посмотрим на набор операторов: $E, A, A^2, \dots$ над векторным пространством $V$.
    Размерность пространства операторов конечномерно(и равно $(\dim V)^2$ так как
    оператор \hyperref[thm:Линейное отображение определяется действием на базисных векторах]
    {определяется однозначно двумя наборами базисов}), поэтому
    с какого-то момента у нас появится линейная зависимость данного набора операторов.
    А значит существует многочлен, который аннулирует $A$, назовём его $g$.
    Так как $K$ алгебраически замкнуто, то у этого многочлена есть разложение на простейшие
    $g(x) = \prod (x - \lambda_i)^{\alpha_i}$, а значит исходное пространство раскладывается 
    \hyperref[thm:О аннулирующем операторе]{по теореме выше} как 
    \[
        V = \ker (A - \lambda_1 E)^{\alpha_1} \oplus \dots \oplus \ker (A - \lambda_k E)^{\alpha_k}
    .\]
\end{follow}
\subsection{Жорданов базис}
\begin{motivation}
    Хотим понять, как устроено действие оператора $A$ на подпространстве $\ker (A - \lambda_iE)^{\alpha_i}$.
    Иначе говоря к какому виду можно привести матрицу оператора $A$ в этом случае.
\end{motivation}
\begin{remark}
    $A - \lambda_iE$ на пространстве $\ker(A - \lambda_iE)^{\alpha_i}$ является нильпотентом.
\end{remark}
\begin{proof}
    Просто по определению $\ker (A - \lambda_i E)^{\alpha_i}$, любой вектор из этого
    подпространства будет переходить при воздействии на него оператором 
    $(A - \lambda_i E)^{\alpha_i}$ в ноль, что эквивалентно тому, что 
    $(A - \lambda E)^{\alpha_i}$ является нулевым оператором.
\end{proof}
\begin{follow}
    Таким образом, благодаря предыдущему замечанию и следствию теоремы выше,
    вся классификация сводится к классификации нильпотентных элементов.
\end{follow}

К сожалению в рамки курса не удалось уместить вывод классификации приведённой ниже,
поэтому будет приведена просто классификация без доказательств.
Заметим, что \hyperref[def:жорданова клетка]{Жорданова клетка} $J_k(\lambda)$ 
подходит на роль нильпотентов образующие подпространство из замечания выше,
если из неё вычесть $\lambda$, так как $(J(\lambda) - \lambda)^k = 0$, так как
ранее(\hyperref[fix:nilpotent]{внутри доказательства одного из утверждений})
было показано, что это верно вообще для любой верхнетреугольной матрицы с нулями
на диагонали.

\begin{theorem}[О жордановом базисе]
    Пусть $A\colon V\mapsto V$. $K$~--- алгебраически замкнуто. Тогда существует базис $e$,
    такой, что 
     \[
         J = [A]^e_e =
         \begin{pNiceMatrix}
             \Block[borders={bottom,right}]{1-1}{J_{k_1}(\lambda_1)} & & \Block{2-2}<\LARGE>{0}\\
             \Block{3-2}<\LARGE>{0} & \Ddots\\
             \\
             & & & \Block[borders={left,top}]{1-1}{J_{k_n}(\lambda_n)}
         \end{pNiceMatrix}
    .\] 
    \begin{definition}
        Такое представление оператора $A$ будем называть Жордановой формой.
    \end{definition}
    \begin{definition}
        Такой базис $e$ будем называть Жордановым базисом.
    \end{definition}
    Причём такой вид матрицы $[A]^e_e$ единственный с точностью до перестановки блоков.
    Иначе говоря, какие бы два Жордановых базиса мы не взяли, то Жорданова форма будет 
    одинакова с точностью до перестановки блоков(Жордановых клеток).
\end{theorem}
\begin{proof}
    Докажем единственность, а существование сказали посмотреть в конспекте(не в этом). 
    Для этого зафиксируем Жорданов базис $e$ и докажем, что для него все числа 
    $\lambda_i$ и размеры $k_i$ Жордановых блоков однозначно определяются матрицой $A$.
    Пусть $\gamma$ это набор чисел, в котором есть все числа из $\lambda$, но при этом
    все числа в нём различны.

    Посмотрим какие числа могут стоять на диагонали оператора $A$ в Жордановой форме $J = [A]^e_e$.
    Так как характеристический многочлен оператора 
    \hyperref[rem:Характеристический многочлен не зависит от базиса]{не зависит от базиса}, тогда
    $\chi_A(t) = \chi_J(t) = \pm\prod\limits_{i=0}^{n}{(t-\lambda_i)^{k_i}}=
    \pm\prod\limits_{i=0}^{m}{(t-\gamma_i)^{\alpha_i}} \Rightarrow \lambda_i, \gamma_i$
    являются собственными числами(\hyperref[stm:Критерий для собственного числа]{по утверждению}).


    Знаем, что у каждого $\gamma_i$ есть алгебраическая кратность $\alpha_i$, которая опять таки
    не зависит от выбора базиса, так как характеристический многочлен
    \hyperref[rem:Характеристический многочлен не зависит от базиса]{не зависит от базиса}.
    Каждое $\alpha_i$ для матрицы $J$ задаёт сумму размеров Жордановых блоков с собственным 
    числом равным $\gamma_i$,
    это следует просто по тому, как мы считаем $\chi_J(t)$. Этот результат можно записать
    следующим образом: 
    \[
        \alpha_i = \sum\limits_{\substack{j=0\\\lambda_j = \gamma_i}}^{n} k_j
    .\]

    Теперь посмотрим на геометрическую кратность $\gamma_i$. Она равна следующему:
    $\dim \ker \left([A]^e_e - \gamma_i E\right) = \dim \ker (J - \gamma_i E)$, 
    что равно количеству клеток таких, что $\lambda_i = \gamma_i$,
    так как только на этих клетках на главной диагонали возникнут нули, а каждая такая клетка
    добавит по 1 в размерность ядра.

    То есть на данный момент мы для каждого $\gamma_i$ знаем количество блоков и их суммарный
    размер, но в итоге хотим однозначно восстановить размеры всех блоков c $\gamma_i$.

    Давайте зафиксируем $\gamma_i$ и будем проводить следующие рассуждения только для него,
    для остальных по аналогии.
    Теперь выпишем все $k_j$ для которых $\lambda_j = \gamma_i$ в порядке не возрастания 
    и получим следующее: $k_{j_1} \ge k_{j_2} \ge \dots \ge k_{j_s}$, это все размеры блоков,
    для которых $\lambda_j = \gamma_i$. 
    Теперь составим таблицу, где $l$ столбцу будет соответствовать $j_l$ Жорданов блок,
    таким образом $l$ столбец будет иметь высоту $k_{j_l}$, а всего столбцов будет $s$.
    \[
    \NiceMatrixOptions{cell-space-top-limit=3pt}
    \begin{NiceTabular}{*{6}{c}}[corners=NE,hvlines,last-row]
         $e_{4,1}$&$e_{4,2}$\\
         $e_{3,1}$&$e_{3,2}$&$e_{3,3}$&$e_{3,4}$\\
         $e_{2,1}$&$e_{2,2}$&$e_{2,3}$&$e_{2,4}$\\
         $e_{1,1}$&$e_{1,2}$&$e_{1,3}$&$e_{1,4}$&$e_{1,5}$&$e_{1,6}$\\
         $k_{j_1}$ & $k_{j_2}$ & \Hdotsfor{3} & $k_{j_6}$
     \end{NiceTabular} \quad \text{пример для } s=6
    \]
    Для этого выпишем 
    все вектора из $e$ в таблицу следующим образом: $e_{*,l}$ это все вектора, которые
    образуют $j_l$ Жорданов блок(они все будут с собственным числом равным $\gamma_i$). Их
    ровно $k_{j_l}$, так как в матрице $J$ есть Жорданов блок именно такого размера,
    где столбцы матрицы $J$ суженные на этот блок не что иное как $e_{*,l}$. 
    Обозначим $N = (A - \gamma_i E)$
    и посмотрим как этот оператор действует на векторах из $e_{*,l}$. Если нарисовать
    картинку(приведена ниже), то легко видеть, что:
    \[
        \begin{cases}
            Ne_{1, l} = 0\\
            Ne_{2, l} = e_{1, l}\\
            Ne_{3, l} = e_{2, l}\\
            \vdots\\
            Ne_{k_{j_l}, l} = e_{k_{j_l} - 1, l}
        \end{cases}
    \]
    А это значит, что если посмотреть на $\ker N^{lvl}$, то при увеличении $lvl\mapsto lvl + 1$
    ядро будет увеличиваться на количество элементов, которые находились в таблице
    выше на строке $lvl$, то есть в ядро попадут все $e_{lvl, *}$. Следовательно мы можем
    следить за размерностью ядра $\ker N^{lvl}$ и восстанавливать количество блоков следующим
    образом: $\ker N^{lvl+1} - \ker N^{lvl}$ это количество блоков размера больше $lvl$. 
    Это факт уже позволяет нам однозначно восстановить размер каждой Жордановой клетки.

    Понимаем, что любые другие $e$ никогда не попадут в ядро $N$ и его любых степеней,
    так как они будут умножаться на верхнетреугольную матрицу без нулей на диагонали.
    
    Обещанная картинка(где $e_i$ произвольный вектор Жордановой клетки с коэффициентом $\gamma$):
    \[
        (A - \gamma E) \cdot e_i = 
        \begin{pNiceMatrix}
            \Block[borders={bottom,right}]{1-1}{J_{k_1}(\lambda_1) - \gamma E} & & & \Block{2-2}<\LARGE>{0}\\
             & \Ddots\\
            & & \Block[borders={left,top,bottom,right}]{1-1}{J_{k_i}(\gamma) - \gamma E} \\
            \Block{2-2}<\LARGE>{0} & & & \Ddots\\
            & & & & \Block[borders={left,top}]{1-1}{J_{k_n}(\lambda_n) - \gamma E}
        \end{pNiceMatrix} \cdot
        \begin{pmatrix}
            0\\
            \hline
            \vdots\\
            \hline\\[-3mm]
            0\\
            \hline\\[-3mm]
            X \\
            \hline\\[-3mm]
            0\\
            \hline
            \vdots\\
            \hline\\[-3mm]
            0
        \end{pmatrix}
        =
        \begin{pmatrix}
            0\\
            \hline
            \vdots\\
            \hline\\[-3mm]
            0\\
            \hline\\[-3mm]
            (J_{k_i}(\gamma) - \gamma E) \cdot X \\
            \hline\\[-3mm]
            0\\
            \hline
            \vdots\\
            \hline\\[-3mm]
            0
        \end{pmatrix}
   \]
   \[
        (J_{k_i}(\gamma) - \gamma E) \cdot X = 
         \begin{pNiceMatrix}
             0 & 1 & 0 & \Cdots & 0\\
             0 & \Ddots & \Ddots & \Ddots & \Vdots\\
             \Vdotsfor{2}&\Ddots& & & 0\\
                 & & & & 1\\
             0 & \Hdotsfor{2} & 0 & 0\\
         \end{pNiceMatrix} 
         \begin{pNiceMatrix}[first-col]
             &0\\
             &\Vdots\\
             &0\\
             j \rightarrow & 1\\
             &\gamma\\
             &0\\
             &\Vdots\\[-3mm]
             &0
         \end{pNiceMatrix}
         =
         \begin{pNiceMatrix}[first-col]
             &\Vdots\\
             &0\\
             j-1 \rightarrow & 1\\
             &\gamma\\
             &0\\
             &\Vdots\\[-3mm]
             &\Vdots\\
             &0
         \end{pNiceMatrix}
    \]
\end{proof}
