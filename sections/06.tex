\section{Лекция 21.03}
\subsection{Определение алгебры}
\begin{remark}
    По результатом прошлой лекции мы поняли,
    что любое элементарное преобразование системы
    это умножение на верхне или нижне треугольную матрицу.
\end{remark}
\begin{remark}
    Заметим, некоторые свойства верхнетреугольных матриц. $LT_n(K)\subseteq M_n(K)$ 
    \begin{enumerate}
        \item Подкольцо
        \item Подпространство
    \end{enumerate}
\end{remark}
\begin{proof}
    Докажем, что это подкольцо, а именно произведение нижнетреугольных матриц опять таки
    нижнетреугольная. 
    \[
        A \times B = C
    \] $A, B \in LT_n(K)$, необходимо доказать, что $C\in LT_n(K)$. 
    Для этого необходимо показать, что $c_{i, j} = 0, \forall j > i$.
    \[
        c_{i,j} = \sum\limits_{k=1}^{n}{a_{i,k} b_{k,j}}
    \]
    Так как $A, B$~--- нижнетреугольные, то из этого следует, что 
    $a_{i,k} = 0, \forall i < k,\quad b_{k, j} = 0, \forall k < j$, откуда
    очевидно, что при $j > i$ $a_{i,k}b_{k,j} = 0$.

    Получается, что доказали замкнутость умножения. Замкнутость сложения очевидна,
    единица в кольце, это просто единичная матрица. 

    Отдельно стоит отметить, что это кольцо \textbf{не коммутативно}.
\end{proof} 
\begin{motivation}
    Заметим, что у нас получился объект, который является и кольцом и пространством, давайте
    введём для этого случая специальное определение.
\end{motivation}
\begin{definition}
    $R$~--- кольцо, $K$~--- поле.
    $\cdot\colon K\times R\mapsto R$. Тогда $R$ называется алгеброй, если 
     \begin{enumerate}
         \item $\left(R,+,\cdot\right)$~--- векторное пространство.
         \item $\lambda(A\cdot B) = (\lambda A)\cdot B = A\cdot (\lambda B), \forall \lambda\in K, A,B\in R$
    \end{enumerate}
\end{definition}
\begin{example}
    $\C$~--- алгебра над $\R$. В общем случае: $K\subseteq L$~--- расширение полей.
\end{example}
\begin{statement}
     Любое конечномерное пространство может быть достроено до алгебры:
     а именно пространство квадратных матриц размера $\dim U$.
\end{statement}
\subsection{Обратные матрицы для верхне-нижнетреугольных}
\begin{statement}[Обратная матрица к нижнетреугольной также нижнетреугольная]
     $L\in LT_n(K)$. Если $L$~--- обратимая, тогда $L^{-1}\in LT_n(K)$.
\end{statement}
\begin{proof}
    Есть 3 доказательства этого факта.
    \begin{enumerate}
        \item Алгебраическое доказательство.\\
            $$L = 
            \begin{pmatrix}
                \lambda_1&&&0\\
                *&\lambda_2&&\\
                \vdots&\ddots&\ddots&&\\
                *&\cdots&*&\lambda_n
            \end{pmatrix}$$
            Знаем, что для обратимость матрицы эквивалентна $\rk L = n$, а значит все строчки и столбцы
            должны быть линейно независимыми, откуда следует, что $\lambda_i \not= 0, \forall i$, так как иначе
            получалось бы, что $\lambda_i = 0$, а значит строчки $1\dots i$ линейно зависимые(так как
            у нас $i$ строчек в пространстве размерностью $i - 1$).

            Зная, что $\lambda_i \not= 0$ постараемся привести матрицу к виду, что все элементы на диагонали 
            равны нулю.
            Тогда если мы определим матрицу $D$ следующим способом,
            \[
            D = \begin{pmatrix}
                \lambda_1&&&0\\
                &\lambda_2&&\\
                &&\ddots&&\\
                0&&&\lambda_n
            \end{pmatrix}
            .\] 
            то получим, что $D^{-1} L$ имеет единицы на главной диагонали. Но под главной диагональю у этой матрицы будет
            не понятно что, давайте обозначим это за $N$, итак: $D^{-1}L = E_n + N$.

            Из этого разложения легко видеть, чем является $L^{-1}$, а именно: $L^{-1} = (E_n + N)^{-1}D^{-1}$.
            Осталось доказать, что она является нижнетреугольной.
            Из матанализа и(или) дискретной математики знаем, что 
            \[
                (1 + x)^{-1} = \frac{1}{1+x} = 1 - x + x^2 +\dots +(-1)^nx^n\dots
            \]
            Давайте попробуем применить данный трюк но в пространстве матриц.
            Но говорить о бесконечной сумме нехорошо, поэтому давайте убедимся,
            что с какого-то момента хвост этой суммы равна нулю.

            Заметим, что на главной диагонали матрицы $N$ стоят нули. Поэтому, хочется
            показать, что $N^n = 0$, тогда наша сумма является конечной.
            Посмотрим на подпространства $\langle e_n,\dots, e_i\rangle = U_i$.
            Тогда несложно показать, что $N(U_i)\subseteq U_{i+1}$, где $N$ рассмотрено как линейное отображение. 
            \[
                \begin{pmatrix}
                    0 & 0 & \dots & 0\\
                    * & 0 & \ddots & \vdots\\
                    \vdots & \ddots & \ddots & 0\\
                    * & \dots & * & 0
                \end{pmatrix}
                \setlength{\extrarowheight}{0cm}
                \begin{pNiceMatrix}[small,cell-space-limits=0pt,last-col=2]
                    0 \\
                    \Vdots\\
                    0\\[0.2pt]
                    * & \leftarrow i\\
                    \Vdots\\
                    \\
                    *\\
                \end{pNiceMatrix} =
                \begin{pNiceMatrix}[small,cell-space-limits=0pt,last-col=2]
                    0 \\
                    \Vdots\\
                    \\
                    0\\
                    * & \leftarrow i + 1\\
                    \Vdots\\
                    *\\
                \end{pNiceMatrix}
            \]
            Иначе говоря, при умножении произвольного $u \in U_i$ на $N$ мы получаем вектор из пространства $U_{i + 1}$.
            Таким образом, на каждом шаге мы 
            отсекаем часть нашего пространства и после $n$ умножений обязательно получим нулевой вектор. Ну а так 
            как матрица это просто набор векторов, то достаточно показать это для вектора и для матрицы это следует
            автоматически.

            То есть $N^n = 0$.  Теперь убедимся, что сумма  $E - N + \dots + (-1)^{n-1}N^{n-2}$ действительно обратный элемент
            к  $E + N$. Ну очевидно это так, давайте распишем:
            \[
                \begin{gathered}
                    \left(E_n - N + \dots + (-1)^{n-1}N^{n-1}\right)(E_n + N)=\\=
                    \left(E_n - N + \dots + (-1)^{n-1}N^{n-1} + N - N^2 + \dots + (-1)^{n-1}N^n\right)= E
                \end{gathered}
            \]
            То есть, все элементы при степенях меньших $n$ сократятся, а элемент при $N^n$ можно 
            выкинуть, так как $N^n = 0$.
        \item
            Приведём другое доказательство, которое использует метод Гаусса.\\
             \[
            L = 
            \begin{pmatrix}
                \lambda_1&&&0\\
                *&\lambda_2&&\\
                \vdots&\ddots&\ddots&\\
                *&\dots&*&\lambda_n
            \end{pmatrix}
             \] 
             $\lambda_i \not= 0,\forall i$, иначе матрица необратима(по аналогии с первым доказательством).

             Заметим, что при применении метода Гаусса на этой матрицы, мы никогда не
             меняем местами строки, так как $a_{i,i} \not= 0$, из-за того, что матрица
             нижнетреугольная и элементарным преобразованием первого типа в ходе алгоритма
             Гаусса элементы на диагоналях изменяться не будут.

             Причём в данной ситуации все матрицы элементарных преобразований будут нижнетреугольными, 
             так как матрицы второго типа мы тут не используем, матрица третьего преобразования просто всегда
             является нижнетреугольной, а матрица первого типа в данном случае тоже будет являться нижнетреугольной,
             так как мы всегда прибавляем вышестоящую строчку к нижестоящей.

             Это даёт нам понимание факта, что на всём времени работы алгоритма матрица остаётся нижнетреугольной.
             Тогда можно записать следующее, где за $L_i$ обозначены матрицы элементарных преобразований, а 
             $D$~--- диагональная матрица(см первое доказательство).
             \[
                 L_n\ldots L_2L_1L=D
             \]
             Хотим из этого выражения выразить $L^{-1}$. Для этого множим на $L^{-1}$ справа
             и на $D^{-1}$ слева. В итоге получили: $D^{-1}L_n\ldots L_2L_1 = L^{-1}$.
             Цель достигнута, нашли обратную матрицу в виде композиции элементарных преобразований и чего-то похожего на решение
             системы уравнений. Ну и опять таки она нижнетреугольная, как произведение нижнетреугольных.
    \end{enumerate}
\end{proof}
\begin{definition}
    $GL_n(K)$~--- множество всех обратимых матриц размера $n\times n$.
\end{definition}
\subsection{LU разложение в методе Гаусса}
Хотим улучшить метод Гаусса, для случая, где все элементы главной
диагонали не равны нулю, так как действительно если мы работаем с действительными числами ноль на главной
диагонали возникает достаточно редко. Это избавляет нас от перестановки строк(второго элементарного преобразования).

Помимо этого, будем предполагать, что $A\in GL_n(K)$.
Тогда после работы Гаусса $L_k\ldots L_1A = U$, где все $L_i$~--- нижнетреугольные,
$U$~--- верхнетреугольная просто по инварианту алгоритма Гаусса.
Обозначим за $L = (L_k\ldots L_1)^{-1}$, она также является нижнетреугольной по 
\hyperref[stm:Обратная матрица к нижнетреугольной также нижнетреугольная]{только что доказанному утвердждению.}
$A = LU$, где $L$~--- нижнетреугольная матрица, причём у $L$~--- единицы на диагонали, так как у всех матриц элементарных
преобразований тоже на диагонали находятся единицы.
Поймём, когда это разложение существует, в том плане, когда выполнены все критерии, которые мы наложили на матрицу 
$A$ в самом начале.

\begin{definition}
    Главной подматрицей матрицы $A$ размера $s$ назовём левую верхнюю подматрицу
    размера $s\times s$.
\end{definition}
\begin{remark}
    Далее по курсу невырожденными матрицами будем называть необратимые.
\end{remark}
\begin{theorem}
    Пусть $A\in GL_n(K)$ тогда равносильны:
    \begin{enumerate}
        \item $\exists U\in UT_n(K), L\in LT_n(K)\colon A = LU$
        \item все главные подматрицы обратимы
        \item В методе Гаусса не используются перестановки строк(преобр 2 типа) \end{enumerate}
\end{theorem}
\begin{proof}\leavevmode
    \begin{itemize}
        \item $3\Rightarrow 1$ уже доказано выше
        \item  $1\Rightarrow 2$ докажем\\
            Заметим, что раз уж $A$~--- обратимая, то $L, U$~--- тоже обратимые 
            \hyperref[stm:Базовый критерий обратимости]{по базовому критерию обратимости}(так как
            обратимость эквивалентна $\rk A = n$), а это значит, что на главных диагоналях $L, U$ нет нулей.
            \[
            \left(\begin{array}{c|c}
                    \hat{A} & * \\
                    \hline
                    * & *
            \end{array}\right) = A = LU = 
            \left(\begin{array}{c|c}
                    \hat{L} & 0\\
                    \hline
                    * & \bar{L}
            \end{array}\right)
            \left(\begin{array}{c|c}
                    \hat{U} & *\\
                    \hline
                    0 & \bar{U}
            \end{array}\right) =
            \left(\begin{array}{c|c}
                    \hat{L} \hat{U} & *\\
                    \hline
                    * & *
            \end{array}\right)
            \] 
            Где матрицы $\hat{L}, \bar{L}, \hat{U}, \bar{U}$ являются нижне и вехнетреугольными соответственно и не
            имеют на диагоналях нули.
            Тогда получается, что их произведение (а именно главная подматрица $\hat{A}$) обратима как 
            произведение обратимых матриц.
        \item $2\Rightarrow 3$ Докажем по индукции\\
            Утверждение: пусть главная подматрица размера $k$~--- обратима и все меньшие, тоже
            обратимы, тогда в методе Гаусса не используется перестановка строк в первых $k$ итерациях.
            База очевидна. Переход: в первых $k$ шагах мы первые верхние строчки($<k$) прибавляли к
            нижним($>k$). В исходной матрицей первые $k$ столбцов линейно независимы, а значит после
            применения метода Гаусса первые $k$ столбцов тоже линейно независимы. Но, если $k$ элемент
            равен нулю и требуется перестановка, то получается противоречие с линейной независимостью.
    \end{itemize}
\end{proof}
\begin{statement}[О единственности LU разложения]
    $A = L_1U_1, A = L_2U_2$, причём $L_1,L_2$~--- нижнетреугольные, $U_1, U_2$~--- верхнетреугольные,
    причём в $L_1,L_2, U_1,U_2$ нет нулей на главной диагонали. Тогда $U_1=U_2, L_1 =L_2$.
\end{statement}
\begin{proof}
    $L_1U_1 = L_2U_2\Rightarrow L_2^{-1}L_1 = U_2U_1^{-1}$. Слева у нас 
    нижнетреугольная матрица, а справа верхнетреугольная, тогда равенство значит,
    что они обе на самом деле просто диагональные, причём с единицами на диагонали, 
    а это значит, что $L_1U_1 = E_n$.
\end{proof}
\begin{remark}
    Теперь давайте поиспользуем наше знание о разложении матрицы на множители для 
    решения системы линейных уравнений.
    Есть разложение $A = LU$.
    Хотим решать $Ax = b$, 
    тогда можно эту систему как систему
    \[
    \begin{cases}
        Ly = B\\
        Ux = y
    \end{cases}
    .\] 
    Каждое из уравнений системы мы умеем решать за $O(n^2)$,
    а находить разложение можно за $O(n^3)$.

    На самом это полезно, когда у нас есть фиксированная матрица $A$ и 
    нам надо решить много уравнений при различных $b$.
    На самом деле можно делать ещё и так:
    $x = A^{-1}b$, такое решается за  $O(n^2)$.
\end{remark}
\begin{motivation}
    TODO Затехать упражнение про инвариант разложения матрицы $A$.
\end{motivation}
\begin{example}
    Часто применяется для решения диффуров. 
    $\frac{d^2f}{dx^2} + u(x)\frac{dt}{dx} = F$, зная, что $f(0) = a_1, f(1) = a_2$.
    В таких случаях обычно ищут приближённое значение $f$ в точках 
    $k\in[0,n], f(\frac{k}{n})=?$. Тогда в исходном уравнении делается замена:
    $$f''(x)\simeq \frac{f(x-h)+f(x+h)-2f(x)}{h^2}$$,
    $$f'(x)\simeq \frac{f(x+h) - f(x - h)}{2h}$$.
    Оказывается, что в таких случаях помогает $LU$ разложение.
\end{example}
\begin{example}
    $P_\sigma(e_i)= e_{\sigma(i)}$~--- матрицы перестановки.
     \[
         (P_\sigma)_{i,j} = \begin{cases}
             1, i = \sigma(j)\\
             0, \text{иначе}
         \end{cases}
    .\]
    Упражнение: доказать, что $A\in GL_n(k), \exists L, U, P\colon PA = LU$. 
    Как будем подбирать эту перестановку? TODO(потерял мысль)
\end{example}
\begin{remark}
    Иногда $LU$ разложение позволяет решать проблемы точности дробных чисел(см Pivotiong).
\end{remark}
\subsection{Определитель}
\begin{motivation}
    Хотим иметь характеристику матрицы, отражающую насколько она близка к обратимой.
\end{motivation}
\begin{remark}
    $\R^3(\R^n)$.
    Тогда матрица будет необратима, когда все её вектора лежат в одной плоскости.
    Давайте зададим параллелипипед следующим образом.
    $D(v_1,\dots, v_n) = \{\lambda_iv_i\mid \lambda\in [0, 1]\}$. Достаточно очевидно,
    что  $Vol(D(v_1,\dots, v_n))=0\Leftrightarrow v_1,\dots, v_n$~--- линейно независимы.
\end{remark}
