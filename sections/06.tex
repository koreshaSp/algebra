\section{Лекция 21.03}
\subsection{Определение алгебры}
\begin{remark}
    По результатом прошлой лекции мы поняли,
    что любое элементарное преобразование системы
    это умножение на верхне или нижне треугольную матрицу.
\end{remark}
\begin{remark}
    Заметим, некоторые свойства верхнетреугольных матриц. $LT_n(K)\subseteq M_n(K)$ 
    \begin{enumerate}
        \item Подкольцо
        \item Подпространство
    \end{enumerate}
\end{remark}
\begin{proof}
    Докажем, что это подкольцо, а именно произведение нижнетреугольных матриц опять таки
    нижнетреугольная. 
    \[
        A \times B = C
    \] $A, B \in LT_n(K)$, необходимо доказать, что $C\in LT_n(K)$. 
    Для этого необходимо показать, что $c_{i, j} = 0, \forall j > i$.
    \[
        c_{i,j} = \sum\limits_{k=1}^{n}{a_{i,k} b_{k,j}}
    \]
    Так как $A, B$~--- нижнетреугольные, то из этого следует, что 
    $a_{i,k} = 0, \forall i < k,\quad b_{k, j} = 0, \forall k < j$, откуда
    очевидно, что при $j > i$ $a_{i,k}b_{k,j} = 0$.

    Получается, что доказали замкнутость умножения. Замкнутость сложения очевидна,
    единица в кольце, это просто единичная матрица. 

    Отдельно стоит отметить, что это кольцо \textbf{не коммутативно}.
\end{proof} 
\begin{motivation}
    Заметим, что у нас получился объект, который является и кольцом и пространством, давайте
    введём для этого случая специальное определение.
\end{motivation}
\begin{definition}
    $R$~--- кольцо, $K$~--- поле.
    $\cdot\colon K\times R\mapsto R$. Тогда $R$ называется алгеброй, если 
     \begin{enumerate}
         \item $\left(R,+,\cdot\right)$~--- векторное пространство.
         \item $\lambda(A\cdot B) = (\lambda A)\cdot B = A\cdot (\lambda B), \forall \lambda\in K, A,B\in R$
    \end{enumerate}
\end{definition}
\begin{example}
    $\C$~--- алгебра над $\R$. В общем случае: $K\subseteq L$~--- расширение полей.
\end{example}
\begin{statement}
     Любое конечномерное пространство может быть достроено до алгебры:
     а именно пространство квадратных матриц размера $\dim U$.
\end{statement}
\subsection{Обратные матрицы для верхне-нижнетреугольных}
\begin{statement}[Обратная матрица к нижнетреугольной также нижнетреугольная]
     $L\in LT_n(K)$. Если $L$~--- обратимая, тогда $L^{-1}\in LT_n(K)$.
\end{statement}
\begin{proof}
    Есть 3 доказательства этого факта.
    \begin{enumerate}
        \item Алгебраическое доказательство.\\
            $$L = 
            \begin{pmatrix}
                \lambda_1&&&0\\
                *&\lambda_2&&\\
                \vdots&\ddots&\ddots&\\
                *&\cdots&*&\lambda_n
            \end{pmatrix}$$
            Знаем, что обратимость матрицы эквивалентна $\rk L = n$, а значит все строчки и столбцы
            должны быть линейно независимыми, откуда следует, что $\lambda_i \not= 0, \forall i$, так как иначе
            получалось бы, что $\lambda_i = 0$, а значит строчки $1\dots i$ линейно зависимые(так как
            у нас $i$ строчек в пространстве размерностью $i - 1$).

            Зная, что $\lambda_i \not= 0$ постараемся привести матрицу к виду, что все элементы на диагонали 
            равны нулю.
            Тогда если мы определим матрицу $D$ следующим способом,
            \[
            D = \begin{pmatrix}
                \lambda_1&&&0\\
                &\lambda_2&&\\
                &&\ddots&\\
                0&&&\lambda_n
            \end{pmatrix}
            .\] 
            то получим, что $D^{-1} L$ имеет единицы на главной диагонали. Но под главной диагональю у этой матрицы будет
            не понятно что, давайте обозначим это за $N$, итак: $D^{-1}L = E_n + N$.

            Из этого разложения легко видеть, чем является $L^{-1}$, а именно: $L^{-1} = (E_n + N)^{-1}D^{-1}$.
            Осталось доказать, что она является нижнетреугольной.
            Из матанализа и(или) дискретной математики знаем, что 
            \[
                (1 + x)^{-1} = \frac{1}{1+x} = 1 - x + x^2 +\dots +(-1)^nx^n\dots
            \]
            Давайте попробуем применить данный трюк но в пространстве матриц.
            Но говорить о бесконечной сумме нехорошо, поэтому давайте убедимся,
            что с какого-то момента хвост этой суммы равна нулю.

            \label{fix:nilpotent}
            Заметим, что на главной диагонали матрицы $N$ стоят нули. Поэтому, хочется
            показать, что $N^n = 0$, тогда наша сумма является конечной.
            Посмотрим на подпространства $\langle e_n,\dots, e_i\rangle = U_i$.
            Тогда несложно показать, что $N(U_i)\subseteq U_{i+1}$, где $N$ рассмотрено как линейное отображение. 
            \[
                \begin{pmatrix}
                    0 & 0 & \dots & 0\\
                    * & 0 & \ddots & \vdots\\
                    \vdots & \ddots & \ddots & 0\\
                    * & \dots & * & 0
                \end{pmatrix}
                \begin{pNiceMatrix}[small,cell-space-limits=0pt,last-col=2]
                    0 \\
                    \Vdots\\
                    0\\[0.2pt]
                    * & \leftarrow i\\
                    \Vdots\\
                    \\
                    *\\
                \end{pNiceMatrix} =
                \begin{pNiceMatrix}[small,cell-space-limits=0pt,last-col=2]
                    0 \\
                    \Vdots\\
                    \\
                    0\\
                    * & \leftarrow i + 1\\
                    \Vdots\\
                    *\\
                \end{pNiceMatrix}
            \]
            Иначе говоря, при умножении произвольного $u \in U_i$ на $N$ мы получаем вектор из пространства $U_{i + 1}$.
            Таким образом, на каждом шаге мы 
            отсекаем часть нашего пространства и после $n$ умножений обязательно получим нулевой вектор. Ну а так 
            как матрица это просто набор векторов, то достаточно показать это для вектора и для матрицы это следует
            автоматически.

            То есть $N^n = 0$.  Теперь убедимся, что сумма  $E - N + \dots + (-1)^{n-1}N^{n-2}$ действительно обратный элемент
            к  $E + N$. Ну очевидно это так, давайте распишем:
            \[
                \begin{gathered}
                    \left(E_n - N + \dots + (-1)^{n-1}N^{n-1}\right)(E_n + N)=\\=
                    \left(E_n - N + \dots + (-1)^{n-1}N^{n-1} + N - N^2 + \dots + (-1)^{n-1}N^n\right)= E
                \end{gathered}
            \]
            То есть, все элементы при степенях меньших $n$ сократятся, а элемент при $N^n$ можно 
            выкинуть, так как $N^n = 0$.
        \item
            Приведём другое доказательство, которое использует метод Гаусса.\\
             \[
            L = 
            \begin{pmatrix}
                \lambda_1&&&0\\
                *&\lambda_2&&\\
                \vdots&\ddots&\ddots&\\
                *&\dots&*&\lambda_n
            \end{pmatrix}
             \] 
             $\lambda_i \not= 0,\forall i$, иначе матрица необратима(по аналогии с первым доказательством).

             Заметим, что при применении метода Гаусса на этой матрицы, мы никогда не
             меняем местами строки, так как $a_{i,i} \not= 0$, из-за того, что матрица
             нижнетреугольная и элементарным преобразованием первого типа в ходе алгоритма
             Гаусса элементы на главной диагонали изменяться не будут.

             Причём в данной ситуации все матрицы элементарных преобразований будут нижнетреугольными, 
             так как матрицы второго типа мы тут не используем, матрица третьего преобразования просто всегда
             является нижнетреугольной, а матрица первого типа в данном случае тоже будет являться нижнетреугольной,
             так как мы всегда прибавляем вышестоящую строчку к нижестоящей.

             Это даёт нам понимание факта, что на всём времени работы алгоритма матрица остаётся нижнетреугольной.
             Тогда можно записать следующее, где за $L_i$ обозначены матрицы элементарных преобразований, а 
             $D$~--- диагональная матрица(см первое доказательство).
             \[
                 L_n\ldots L_2L_1L=D
             \]
             Хотим из этого выражения выразить $L^{-1}$. Для этого множим на $L^{-1}$ справа
             и на $D^{-1}$ слева. В итоге получили: $D^{-1}L_n\ldots L_2L_1 = L^{-1}$.
             Цель достигнута, нашли обратную матрицу в виде композиции элементарных преобразований и чего-то похожего на решение
             системы уравнений. Ну и опять таки она нижнетреугольная, как произведение нижнетреугольных.
    \end{enumerate}
\end{proof}
\begin{definition}
    $GL_n(K)$~--- множество всех обратимых матриц размера $n\times n$.
\end{definition}
\subsection{LU разложение в методе Гаусса}
Хотим улучшить метод Гаусса, для случая, где все элементы главной
диагонали не равны нулю, так как действительно если мы работаем с действительными числами ноль на главной
диагонали возникает достаточно редко. Это избавляет нас от перестановки строк(второго элементарного преобразования).

Помимо этого, будем предполагать, что $A\in GL_n(K)$.
Тогда после работы Гаусса $L_k\ldots L_1A = U$, где все $L_i$~--- нижнетреугольные,
$U$~--- верхнетреугольная просто по инварианту алгоритма Гаусса.
Обозначим за $L = (L_k\ldots L_1)^{-1}$, она также является нижнетреугольной по 
\hyperref[stm:Обратная матрица к нижнетреугольной также нижнетреугольная]{только что доказанному утвердждению.}
$A = LU$, где $L$~--- нижнетреугольная матрица, причём у $L$~--- единицы на диагонали, так как у всех матриц элементарных
преобразований тоже на диагонали находятся единицы.
На самом деле существует необходимый и достаточный критерий существования такого разложения, именно про него будет
следующее утверждение.

\begin{definition}
    Главной подматрицей матрицы $A$ размера $s$ назовём левую верхнюю подматрицу
    размера $s\times s$.
\end{definition}
\begin{remark}
    Далее по курсу невырожденными матрицами будем называть обратимые.
\end{remark}
\begin{theorem}
    Пусть $A\in GL_n(K)$ тогда равносильны:
    \begin{enumerate}
        \item $\exists U\in UT_n(K), L\in LT_n(K)\colon A = LU$
        \item все главные подматрицы обратимы
        \item Во время работы алгоритма Гаусса на матрице $A$ не используются перестановки строк(преобр 2 типа) 
    \end{enumerate}
\end{theorem}
\begin{proof}\leavevmode
    \begin{itemize}
        \item $3\Rightarrow 1$ уже доказано выше
        \item  $1\Rightarrow 2$ докажем\\
            Заметим, что раз уж $A$~--- обратимая, то $L, U$ тоже обратимые. Что несложно доказать
            от обратного \hyperref[stm:Базовый критерий обратимости]{по базовому критерию обратимости}.
            А уже из обратимости матриц можно показать, что, что на главных диагоналях $L, U$ нет нулей. 
            Проведём док-во отсутствия нулей на главной диагонали для $U$, для $L$ почти всё аналогично.

            \begin{lemma}
                Пусть $U\in UT_n(K)$~--- обратимая, тогда $u_{i,i}\not=0, \forall i$.
            \end{lemma}
            \begin{proof}
                Это несложно доказать от обратного: пусть $U_{i,i} = 0$, при этом для всех $j < i, U_{j,j}\not=0$, тогда получается
                что первые $i$ столбцов $U$ лежат в $\mathbb{R}^{i-1}$, следовательно они линейно зависимы. А это значит, что
                $\rk U < n$, а значит она не обратима(противоречие).
            \end{proof}
            Вернёмся к доказательству обратимости главных подматриц $A$. Выпишем следующее равенство:
            \[
            \left(\begin{array}{c|c}
                    \hat{A} & * \\
                    \hline
                    * & *
            \end{array}\right) = A = LU = 
            \left(\begin{array}{c|c}
                    \hat{L} & 0\\
                    \hline
                    * & \bar{L}
            \end{array}\right)
            \left(\begin{array}{c|c}
                    \hat{U} & *\\
                    \hline
                    0 & \bar{U}
            \end{array}\right) =
            \left(\begin{array}{c|c}
                    \hat{L} \hat{U} & *\\
                    \hline
                    * & *
            \end{array}\right)
            \] 
            Где матрицы $\hat{L}, \bar{L}, \hat{U}, \bar{U}$ являются нижне и вехнетреугольными соответственно и не
            имеют на диагоналях нули.
            Тогда получается, что их произведение (а именно главная подматрица $\hat{A}$) обратима как 
            произведение обратимых матриц.
        \item $2\Rightarrow 3$ Докажем по индукции\\
            Пусть $\hat{A}$~--- главная подматрица $A$ размера $k + 1$,
            А $A_k$~--- матрица $A$ к которой применили $k$ итераций алгоритма Гаусса.

            Посмотрим что будет происходить с подматрицей $\hat{A}$ при методе Гаусса запущенным на матрице $A$.
            В первых $k$ шагах алгоритма Гаусса мы прибавляем строчки $\hat{A}$ ($\le k$) к нижестоящим.
            В $\hat{A}$ первые столбцы линейно независимы(так как $\hat{A}$ обратима по условию случая), а значит после
            применения алгоритма Гаусса они останутся линейно независимыми, так как
            \hyperref[2]{линейно независимый набор остаётся таковым при прибавлении к вектору другой вектор из этого набора}.
            А значит, что матрица $\hat{A}_k$ является обратимой. Более того, очевидно что она является верхнетреугольной просто
            по инварианту алгоритма Гаусса. Значит, по лемме выше, получаем, что на главной диагонали матрицы $A$ стоят не нули,
            откуда следует, что перестановка строк никогда не потребуется.
    \end{itemize}
\end{proof}
\begin{statement}[О единственности LU разложения]
    $A = L_1U_1, A = L_2U_2$, причём $L_1,L_2$~--- нижнетреугольные, $U_1, U_2$~--- верхнетреугольные,
    причём в $L_1,L_2$ на главной диагонали стоят единицы. Тогда $U_1=U_2, L_1 =L_2$.
\end{statement}
\begin{proof}
    $L_1U_1 = L_2U_2\Rightarrow L_2^{-1}L_1 = U_2U_1^{-1}$. Слева у нас 
    нижнетреугольная матрица с единицами на диагонали, а справа верхнетреугольная, тогда равенство значит,
    что они обе на самом деле просто диагональные, причём с единицами на диагонали, 
    а это значит, что $L_2^{-1}L_1 = U_2U_1^{-1} = E_n$, откуда очевидно следуют требуемые равенства.
\end{proof}
\begin{remark}
    Теперь давайте поиспользуем наше знание о разложении матрицы на множители для 
    решения системы линейных уравнений.
    Есть разложение $A = LU$.
    Хотим решать $Ax = b$, 
    тогда можно это уравнение как систему
    \[
    \begin{cases}
        Ly = b\\
        Ux = y
    \end{cases}
    .\] 
    Каждое из уравнений системы мы умеем решать за $O(n^2)$ так как в случае треугольных матриц правильно реализованный
    алгоритм Гаусса работает за $O(n^2)$. 

    На самом это полезно, когда у нас есть фиксированная матрица $A$ и 
    нам надо решить много уравнений при различных $b$. 
    В этом случае мы можем один раз найти матрицы $L, U$ при помощи алгоритма Гаусса за $O(n^3)$, после чего решать
    каждое из уравнений за $O(n^2)$.

    На самом деле можно делать ещё и так, иногда так думать удобнее:
    $x = A^{-1}b$, такое решается за  $O(n^2)$.
\end{remark}
\begin{task}
    Докажите, что умножение верхнетреугольных матриц работает за ту же асимптотику, что и умножение произвольных матриц.
\end{task}
\begin{example}
    Часто применяется для решения дифуров, где $f\colon [0, 1]\mapsto \mathbb{R}$ и само уравнение имеет вид:
    $\frac{d^2f}{dx^2} + u(x)\frac{df}{dx} = F$, зная, что $f(0) = a_1, f(1) = a_2$.
    Давайте заменим на дискретное уравнение относительно значения $f$ в некоторых точках. 
    В таких случаях обычно ищут приближённое значение $f$ в точках
    $k\in[0,n], \frac{k}{n}$. Где $n$ некоторая константа, которая чем больше, тем лучше.
    Тогда в исходном уравнении делается замена:
    \[
        h = \frac{1}{n}\quad
        f''(x)\simeq \frac{f(x-h)+f(x+h)-2f(x)}{h^2}\quad
        f'(x)\simeq \frac{f(x+h) - f(x - h)}{2h}
    \] 
    После чего делается подстановка и решается система уравнений.
    Оказывается, что в таких случаях помогает $LU$ разложение для матриц специального вида(ленточных).
\end{example}
\begin{example}
    $P_\sigma(e_i)= e_{\sigma(i)}$~--- матрицы перестановки.
     \[
         (P_\sigma)_{i,j} = \begin{cases}
             1, i = \sigma(j)\\
             0, \text{иначе}
         \end{cases}
    .\]
\end{example}
\begin{task}
    \[
        P_{\sigma\tau} = P_{\sigma} P_{\tau}
    \] 
\end{task}
\begin{task}
   \[
       A\in GL_n(K), \exists L\in LT_n(K), U\in UT_n(K), P\text{~--- матрица перестановки}\colon PA = LU
   \]  
   Hint: это эквивалентно тому, что переставить строчки в $A$ так, что все подматрицы обратимы.
   Hint: $P$ можно взять из метода Гаусса, когда мы переставляем две строки $A$, то добавляем в $P$ 
   соответствующую транспозицию.
\end{task}
\begin{remark}
    Иногда $LU$ разложение позволяет решать проблемы точности дробных чисел(см Pivotiong).
\end{remark}
\subsection{Форма объёма}
\begin{motivation}
    Хотим иметь характеристику матрицы, отражающую насколько она близка к обратимой.
\end{motivation}
\begin{remark}
    Представим, что мы хотим для частного случая $K = \mathbb{R}^3$ придумать критерий обратимости матрицы.
    Вспомнив пока наш единственный \hyperref[stm:Базовый критерий обратимости]{критерий обратимости},
    очевидно, что для того чтобы матрица $A$, образованная
    векторами $v_1, v_2, v_3$, была обратимой, необходимо, чтобы эти вектора не лежали в одной плоскости.
    
    Это можно воспринимать другим образом, а именно: параллелепипед, образованный нашими тремя векторами,
    имеет нулевой объём.
\end{remark}
\begin{definition}
    Параллелепипедом в общем случае назовём следующее множество:
    \[
        D(v_1,\dots, v_n) = \left\{\sum\limits_{i=1}^{n}\lambda_iv_i\mid \lambda\in [0, 1]\right\}
        \] 
\end{definition}
\begin{remark}
    Обобщим нашу ситуацию до $\mathbb{R}^n$.
    Тогда матрица будет необратима, только когда все её вектора образуют параллелепипед нулевого объёма.
    Будем записывать это так:
    \[
        \vol(D(v_1,\dots, v_n))=0\Leftrightarrow v_1,\dots, v_n\text{~--- линейно зависимы} \Leftrightarrow A\notin GL_n(\mathbb{R}^n)
    \]
\end{remark}

