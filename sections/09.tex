\section{Лекция 11.04}
\begin{examples}
    \begin{enumerate}
        \item Преобразование плоскости/пространства.
        \item $K[x]_{\le n} \mapsto K[x]_{\le n}$, где  $f\rightarrow f'$
        \item Марковские цепи(todo убедиться, что ранее было определение, если да, то прикрепить ссылку).
        \item Эволюция во времени.\\
            Пусть есть популяция, которая разделена по возрастам. Пусть $n_1, n_2,\dots, n_k$~--- количество особей каждого
            возраста. Пусть у нас заданы коэффициенты выживаемости, которые показывают, что особь возраста $i$ проживёт
            сколько надо и станет особью возраста $j$. Пусть $f_i$ количество потомков, которое даёт в среднем особь возраста $n_i$.
            $S_i$ коэффициент выживаемости. 
            Хотим понять, как будет выглядеть матрица перехода количества особей с учётом времени. Утверждается, что так($k = 4$):
            \[
            \begin{pmatrix}
                f_1&f_2&f_3&f_4\\
                s_1&0&0&0\\
                0&s_2&0&0\\
                0&0&s_3&0\\
            \end{pmatrix}
            \begin{pmatrix}
                n_1\\
                n_2\\
                n_3\\
                n_4\\
            \end{pmatrix}
             =
             \begin{pmatrix}
                 n'_1\\
                 n'_2\\
                 n'_3\\
                 n'_4
             \end{pmatrix}
            .\] 
            Эта конструкция называется моделью Лесли.
        \item
            Различные операторы в физике.
        \item
            Линейные рекуррентные соотношения.\\
            $x_{n + k} = a_{k-1}x_{n + (k - 1)} + \dots + a_0x_n$.
            Тогда:
            $X_{n + 1} = AX_n$.
    \end{enumerate}
\end{examples}
\begin{motivation}
    Давайте посмотрим на одномерный случай. В самом деле всё элементарно $Av = \lambda\cdot v$, где $\lambda\in K$.
    Тогда легко видеть, что $A^nv = \lambda^n v$. Хотим получить что-то похожее, но в пространствах больших размерностей.
\end{motivation}
\begin{definition}
    $L\colon V\rightarrow V, \lambda\in K, v\not= 0\in V$. Тогда $\lambda$~--- собственное число, а $v$~--- собственный вектор,
    если $Lv = \lambda v$.
\end{definition}
\begin{motivation}
    Почему это понятие удобно. Пусть $v$ какое-то распределение на вершинах графа, на котором есть случайное блуждание.
    Хотим вычислить $P^n v$. $v = c_1v_1 + \dots + c_kv_k$, где все $c_i,v_i$~--- собственные числа и вектора соответственно.
    Тогда $P(\lambda_1\dots \lambda_k) = $.
    Получили существование очень удобной формы.
\end{motivation}
\begin{remark}
    Заметим, что такое возможно не всегда.
    Пусть 
     \[
    A = 
    \begin{pmatrix}
        0& 1\\
        -1&0\\
    \end{pmatrix}
    \text{~--- матрица поворота на 270}\]
    Заметим, что в этой матрице...(todo)
\end{remark}
\begin{motivation}
    Давайте научимся искать собственные числа вектора.
\end{motivation}
\begin{definition}
    $L\colon V\mapsto V$. $det L = det[L]^e_e$, где $e$~--- произвольный базис.
\end{definition}
\begin{statement}
    $\lambda$~--- собственное число для $L \Leftrightarrow det(L - \lambda E) = 0$
\end{statement}
\begin{proof}
    $\exists v\not= 0\colon Lv = \lambda v$, что эквивалентно $\exists v\not=0\colon (L - \lambda E)v = 0$, а это то же
    самое, что $det(L - \lambda E) = 0$, в случае, когда ... todo(дать пояснение второму переходу).
\end{proof}
\begin{definition}
    $L\colon V\rightarrow V$. Тогда характеристическим многочленом от этого оператора 
    называется $\chi_L(t) = det(L - tE)$.
    \[
        \begin{pmatrix}
            a_{1,1}-t&a_{1,2}&\dots&a_{1,n}\\
            a_{2,1} & \ddots & \ddots& \vdots\\
            \vdots & \ddots & \ddots& a_{n-1,n}\\
            a_{n,1} & \dots & a_{n,n-1}& a_{n,n}-t\\
        \end{pmatrix}
    .\] 
\end{definition}
\begin{remark}
    Старший коэффициент это $(-1)^n$
\end{remark}
\begin{remark}
    $[L - tE]^e_e \in M_n(K(t))$. Так удобно говорить, чтобы не зависеть от введённого базиса $e$.
    Из этого следует, что $\chi_L(t)$ действительно многочлен от $t$ над полем $K(t)$.
\end{remark}
\begin{definition}
    $A\in M_n(K)$. Тогда сумма диагональных элементов называется следом матрицы $A$ и обозначается $Tr A$.
\end{definition}
\begin{remark}
    Свободный член $\chi_L(t)$ это $det L$, а при $t^{n-1}$ это $(-1)^{n-1}Tr A$.
    todo(расписать получше, на лекции рассказали на пальцах)
\end{remark}
\begin{remark}
    Если $C$~--- обратимая, а $A$~--- квадратная, тогда:
    $Tr(CAC^{-1}) = TrA$
\end{remark}
\begin{proof}
    $A$~--- линейный оператор, $C$~--- матрица смены базиса todo(посмотреть как правильно это называется).
    А так как след матрицы не зависит от выбора базиса, то верно равенство.
\end{proof}
\begin{remark}
    Прошлое замечание можно обобщить до вида $A\in M_{n\times m}(K), B\in M_{m\times n}(K)$.
    \[
    Tr AB = Tr BA
    .\] 
\end{remark}
\begin{example}
    \[
    A = 
    \begin{pmatrix}
        a&b\\
        c&d
    \end{pmatrix}
    .\] 
    Тогда $\chi_A(t) = t^2 - Tr A\cdot t + det A$
\end{example}
\begin{motivation}
    Давайте подумаем существует ли ситуация, где мы можем рассчитывать на то, что любой вектор раскладывается в сумму собственных.
    Для этого нужно иметь базис из собственных векторов.
\end{motivation}
\begin{theorem}
    $L: V\rightarrow V, v_1\dots, v_k, \lambda_1\dots, \lambda_k$~--- собственные вектора и числа $L$, причём
    $\lambda_i\not= \lambda_j \forall i\not= j$.
    Тогда:  $v_1\dots v_k$ линейное не зависимые
\end{theorem}
\begin{proof}
    Докажем от противного. Предположим что они линейно зависимы. Тогда возьмём наименьшую возможную по количеству элементов
    нетривиальную линейную комбинацию(опускаем максимальное число слагаемых, равных нулю).
    $c_1v_1+\dots+c_kv_k = 0$. Давайте применим к правой и левой части $L$. Получим, следующее равенство
    $0 = c_1\lambda_1v_i+\dots + c_k\lambda_kv_k$. Не умаляя общности $c_1\not=0$ (так как есть ненулевое слагаемое).
    Теперь давайте сделаем следующий трюк: умножим исходное равенство на $\lambda_1$ и вычтем из текущего, тогда получим:
    \[
    0 = 0\cdot v_1 + (\lambda_1 - \lambda_2)c_2v_2 + \dots + (\lambda_1 - \lambda_k) c_k v_k
    .\]
    В этой сумме есть тоже ненулевое слагаемое, так как $\lambda_i \not= \lambda_j$ но это значит, что мы получили
    разложение нуля с меньшим количеством ненулевых слагаемых. Противоречие.
\end{proof}
\begin{follow}
    $L\colon V \mapsto V$, где $V$ векторное пространство над алгебраически замкнутым полем $K$(значит, что количество корней
    любого многочлена равно его степени). Причём все корни $\chi_L(t)$~--- различны.
    Тогда $\exists \text{базис из собственных векторов}$.
\end{follow}
\begin{proof}
    todo(перепроверить,возможно лажа)
    Пусть $v_1\dots v_n$~--- корни многочлена $\chi_L(t)$(из в точности размер пространства $n$).
    $v_1\dots v_n$~--- собственные вектора, а значит линейно независимы по теореме. Получили базис так как есть
    $n$ линейно независимых векторов.
\end{proof}
\begin{definition}
    $L$~--- диагонализируемая, если $\exists$ базис $e\colon [L]^e_e$~--- диагональная.
    \[
        L = 
        \begin{pmatrix}
            \lambda_1&&0\\
            &\ddots &\\
            0& & \lambda_n
        \end{pmatrix}
    .\] 

    Если переписать на язык матриц, то получим $A\in M_n(K)$, значит $\exists C\in GL_n(K)$, значит $C^{-1}AC = 
    \begin{pmatrix}
        \lambda_1&&0\\
        &\ddots &\\
        0& & \lambda_n
    \end{pmatrix} $
\end{definition}
\begin{definition}
    $L\colon V\mapsto V$, $\lambda$~--- собственное число. Тогда:
    \begin{enumerate}
        \item Алгебраическая кратность $\lambda$.\\
            Кратность  $\lambda$ как корня $\chi_L(t)$.
        \item Геометрическая кратность $\lambda$\\
            $\dim Ker(L-\lambda E)$
    \end{enumerate}
\end{definition}
\begin{theorem}[Необходимое и достаточное условие диагонализуемости]
    $L\colon V\mapsto V$ 
    \begin{enumerate}
        \item $\chi_L(t)$~--- раскладывается на $n$ линейных множителей в $K$.
        \item алгебраическая кратность $\lambda$ = геометрическая кратность $\lambda$, $\forall\lambda\text{~--- собственное число}$ 
    \end{enumerate}
    Тогда и только тогда $L$~--- диагонализуемая.
\end{theorem}
\begin{proof}
    $L$~--- диагонализуема $\ora$ свойства.
    \begin{enumerate}
        \item 
            (todo порефакторить тут)
            $e$~--- базис из собственных векторов $L$. Причём множество векторов, которое соответствует одному
            и тому же числу(todo нарисовать матрицу). Разберёмся с $\lambda_1$ с остальными аналогично. Алгебраическая
            кратность числа $\lambda_1$ это количество раз, которое оно встречается на диагонали отображения $L$.
            Посмотрим на геометрическую кратность 
             \[
            \dim Ker
            \begin{pmatrix}
                \text{тут надо нарисовать сложную блочную матрицу}
            \end{pmatrix}
            .\] 
            Значит, что алгебраическая кратность $\lambda_1$ равна геометрической кратности $\lambda_1$.
    \end{enumerate}

    Теперь докажем $\ola$.
    Возьмём $Ker(L - \lambda_i E)$ пусть его размерность это  $k_i$. Пусть $u_{1,i},\dots,u_{k_i,i}$~--- базис этого
    ядра. Благодаря условиям теоремы(знаем, что количество корней
    $\chi_L(t) = n$, а значит сумма алгебраических кратностей равна $n$, ну а сумма 
    геометрических кратностей равна им и тоже равна $n$) мы знаем, что $\sum\limits_{}^{}{k_i} = n$, где $n = \dim L$.
    Тогда: 
    \[
        \begin{gathered}
            \sum\limits_{i,j}^{}{c_{i,j}u_{i,j}} = 0\\
            \sum\limits_{j}^{}{\sum\limits_{i}{c_{i,j}u_{i,j}}} = 0\\
            \text{поймём, что все внутренние суммы равны нулю, так как todo{завершит. доказательство}}
        \end{gathered}
    .\] 
\end{proof}
\begin{remark}
    $f(x_1,\dots, x_n)\not= 0\in \R[x_1\dots x_n]$, то вероятность попасть в множество нулей многочлена равна нулю
    $P[f(x_1,\dots, x_n) = 0]$.
\end{remark}
\begin{remark}
    $f(x) = a_0 + \dots + a_nx^n$ имеет два одинаковых комплексных корня равносильна тому, что 
     $g(a_0,\dots, a_n) = 0$, ($g$ называется дискриминантом).
     Доп. факт(упражнение, подсказка: определитель ВанДеМорта):
     \[
         g = a_n^{2n - 2}\prod\limits_{}^{}{(\lambda_i - \lambda_j)^2}
     \]
\end{remark}
\begin{motivation}
    Давайте поймем, что происходит в ситуации $A^n v$.
\end{motivation}
\begin{statement}
    Пусть $A\in M_n(\C)$~--- диагонализуемая, $v\in \C^n$, тогда $A^kv = c_1\lambda_1^kv_1 +
    \mathcal{O}(\lambda_2^k)$($k\rightarrow \infty$), где $\abs{\lambda_1}\ge \abs{\lambda_2} \ge \dots \ge \abs{\lambda_n}$.
\end{statement}
\begin{proof}
    Очевидно, так как 
    \[
        A^k v = c_1\lambda_1^k v_1 + \dots + c_n \lambda_n^k v_n
    .\] а благодаря тому, что $\abs{\lambda_1} \ge \abs{\lambda_i}, \forall i \not= 1$ все члены, кроме первого могут быть
    записаны как $\mathcal{O}(\lambda_2^k)$.
\end{proof}
\begin{follow}
    \[
        \begin{gathered}
            \lambda_1 \sim \frac{A^{k + 1}v[1]}{A^k v[1]}\\
            \frac{A^kv}{\norm {A^k v}}\rightarrow cv_1
        \end{gathered}
    .\] 
    Таким образом мы можем считать приближённо значение собственных чисел.
\end{follow}
