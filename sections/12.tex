\section{Лекция 16.04}
\begin{motivation}
    Хотим выяснить какой многочлен подходит на роль $g(A)$ в системе.
    $V = \ker p(A) \oplus \ker q(A), (p,q) = 1, g= pq$
\end{motivation}
\begin{theorem}[Гамильтона-Кели]
   $\chi_A(A) = 0$
   Где $K$~--- алгебраически замкнутое(не существенное, есть несложное сведение).
\end{theorem}
\begin{proof}
    Пусть $e$~--- Жорданов базис, тогда $J = [A]^e_e$.
    Хотим показать, что $\chi_A(J) = 0$.
    Выпишем вид этого многочлена: $\chi_J(t) = \pm\prod\limits_{\lambda_i}^{}{(t-\lambda_i)^{\alpha_i}}$
    заметим, что $\alpha_i$ больше или равна всех возможных размеров Жордановых клеток 
    для $\lambda_i$.
    Тогда можем посчитать следующее:
    $\chi_J(J_{k_i}(\lambda_i))$, где $k_i \le \alpha_i$.
    Наш многочлен это произведения простых скобочек, поэтому можем посчитать для
    каждого и перемножить. 

    Давайте выберем множитель, где $t= J_{k_i}(\lambda_i)$.
    Тогда получим следующее:
     \[
         (t - \lambda_i)^{\alpha_i}  = 
         \begin{pmatrix}
             0 & 1 & \dots & 0\\
             0 & 0 & 1 & \dots\\
             \vdots & \ddots & \ddots & \vdots\\
             0 & \dots & 0 & 1\\
             0 & 0 & 0 & 0\\
         \end{pmatrix}
    .\] 
\end{proof}

\subsection{Билинейные и квадратичные формы}
\begin{definition}
    $V$~--- пространство.
    Пусть $h\colon V \times V \mapsto K$ причём полилинейное, тогда $h$ будем называть
    билинейной формой.
\end{definition}
\begin{remark}
    $e$~--- базис.
    Тогда $h(e_i, e_j)$ однозначно характеризуют нашу билилейную форму.
    Из этого возникает следующее определение.
\end{remark}
\begin{definition}
    Матрица заданная как: $a_{i,j} = h(e_i, e_j)$ называется матрицой билинейной формы.
    Более того, верна следующая формула:
    \[
        h(u, v) = [u]^T_eA[v]_e
    .\] 
    Докажем её, положив $x = [u]_e,\quad y = [v]_e$
     \[
        h(u, v) = x^T A y
    .\] 
    Расписав произведение матриц, получим, что:
    \[
        h(u, v) = \sum\limits_{i, j}^{}{x_i y_j h(e_i, e_j)}
    .\] 
\end{definition}
\begin{motivation}
    Чаще всего билинейные формы возникают вместе со скалярным произведением 
    в $\R^n$. Причём скалярное произведение тут стоит понимать в общем плане для
    нормированных пространств, например $C\left([0, 1]\right) f, g \rightarrow \int\limits_{0}^{1}{f(x)g(x)\ dx}$
    тоже является скалярным произведением. Более того, можно это довести до следующего
    общего вида:
    $\int\limits_{0}^{1}{f(x)g(x) w(x)\ dx}$, где $w\colon [0, 1]\mapsto \R_{> 0}$,
    причём непрерывная.
\end{motivation}
\begin{definition}
    \item Достаточно часто(но не всегда) возникает симметричность
        $h(u,v) = h(v,u), \forall u,v$ 
\end{definition}
\begin{remark}
    Оказывается не так уж и просто придумать пример несимметричного
    (но вот такое пример годиться):
    \[
        x^T
        \begin{pmatrix}
            0 & -1\\
            1 & 0\\
        \end{pmatrix} y
    \]
\end{remark}
\begin{remark}
    $h$~--- симметричное тогда и только когда $A$~--- симметричная матрица.
\end{remark}
\begin{proof}
    TODO(очевидный пруф)
\end{proof}
\begin{definition}
    Форма называется положительно определённой, если $h(x, x) > 0, \forall x\not=0$
\end{definition}
\begin{remark}
    Удобство положительно определённой формы позволяет легко раскладывать пространства в прямую сумму.
    Например можно думать о разложении  $\R^2$ на два одномерных пространства. Пусть у нас есть
    вектор $x$ TODO(пример с двумя прямыми на плоскости(рисунок????))
\end{remark}
\begin{definition}
    $x \perp_h y$(вектор $x$ ортогонален вектору $y$) если $h(x,y) = 0$, где $h$~--- симметричная 
    билинейная форма.
\end{definition}
\begin{definition}
    Пусть $h$~--- симметричная билинейная форма, $U\le V$, то $U^{\perp} = 
    \{x\in V \mid \forall y \in U, x\perp y = 0\}$ называется ортогональным дополнением.
\end{definition}
\begin{theorem}
    $K = \R$, $h$~--- симметричное и положительно определённое, тогда 
    $U \le V \Rightarrow V = U \oplus U^{\perp}$.
\end{theorem}
\begin{proof}\leavevmode
    \begin{enumerate}
        \item
        $U\cap U^{\perp} = \{0\}$
        Так как если предположить противное, тогда $0 = h(x,x) > 0$, противоречие.
        \item 
        $\dim U + \dim U^{\perp} = \dim V$
        Докажем два неравенства. Заметим, что в одну сторону неравенство есть
        по первому пункту(а именно $\dim U + \dim U^{\perp} \le V$).

        Для доказательства другого неравенства надо показать, что $U^{\perp}$ является достаточно
        большим. Но просто по определению $h(x, y) = 0 \Rightarrow x\in U$, а это значит, что наше
        пространство задаётся при помощи $\dim U$ уравнений по замечанию ниже.

        \begin{remark}
            Если $e_1,\dots, e_k$~--- базис $U$, 
            $x\in U^{\perp}$ эквивалентно тому, что $x \perp e_i, \forall i$.
        \end{remark}

        А это значит, что так как $\dim U^{\perp} = \dim \ker \ge \dim (V - K)$, то требуемое
        неравенство $\dim U + \dim U^{\perp} \ge V$
    \end{enumerate}
\end{proof}
\begin{remark}
    Заметим, что в ситуации с подстановкой одинаковых элементов получаем следующее:
    $h(x,x) = x^TAx$, что является однородным многочленом степени 2.
\end{remark}
\begin{definition}
    $V$~--- векторное пространство над $K$. $q\colon V\mapsto K$. 
    в $\forall$ системе координат это однородный многочлен степени 2.
    Тогда $q$~--- квадратичная форма.
\end{definition}
\begin{remark}
    Предполагается, что $char K \not= 2$ сейчас и далее.
\end{remark}
\begin{remark}
    Квадратичный многочлен в координатах имеет следующий вид:
    $q(x) = \sum\limits_{i\le j}^{}{b_{i,j} x_i x_j}$
    Более того, матрица $B$ является симметричной.
\end{remark}
\begin{remark}
    Хотим связать квадратичные формы с билинейными.
     \[
     a_{i,j} = 
     \begin{cases}
         \frac{b_{i,j}}{2}, i < j\\
         \frac{b_{j,i}}{2}, i > j\\
         b_{i,i}
     \end{cases}
    .\] 
    В чём же удобство такого определения? Примерно в следующем:
    \begin{enumerate}
        \item
            $x^TAx = q(x)$
        \item
             $A = A^T$
    \end{enumerate}
    Получаем, что существует взаимо однозначное сопоставление между
    симметричными билинейными формами, квадратичными формами.
\end{remark}
\begin{statement}
     \[
    h(x, y) = \frac{1}{2}(g(x + y) - g(x) - g(y))
    .\] 
\end{statement}
\begin{proof}
    упражнение ;)
\end{proof}
\begin{motivation}
    Хотим навести какую нибудь классификацию для случая, когда $K = \R$.
    Для этого посмотрим как меняются квадратичные и билинейные формы при переходе из одной матрицы в другую.
\end{motivation}
\begin{statement}
    $q$~--- квадратичная форма. $e$~--- базис $x^TAx$, $f$~--- базис $x^TBy$.
    Давайте выразим $x$ следующим образом: $x = Cy$, где $C = [id]^f_e$.
    Откуда следует, что $(Cy)^TACy = y^T(C^TAC)y$
\end{statement}
\begin{statement}
    Пусть 
     \[
         A = 
         \begin{pmatrix}
             \lambda_ 1 & & 0 \\
            & \ddots & \\
            0& & \lambda_n
         \end{pmatrix}
    .\] 
    Тогда $q(x) = \sum\limits_{i=1}^{n}{\lambda_i x_i^2}$.

    После этого можем утверждать о попарной ортогональности собственных векторов.
    Так как вне диагональные элементы это как раз значения $h(x,y)$ на базисных векторах.
\end{statement}
\begin{definition}
    $e$~--- базис $V$. $h\colon V\times V\rightarrow K$, причём $h$~--- симметричная.
    Тогда будем называть базис  $e$ ортогональным, если $e_i\perp e_j, \forall i\not=j$.
\end{definition}
\begin{theorem}
    $q\colon V \mapsto K$~--- квадратичная форма. Тогда существует базис $e$ такой, что
    матрица квадратной формы диагональна.
\end{theorem}
\begin{proof}
    Распишем форму в координатах:
    \[
        q(x) = \sum\limits_{}^{}{a_{i,j} x_i x_j} = a_{1,1}x_1^2 + 2a_{1,2}x_1x_2 + \dots + 2a_{1,n}x_1x_n +
        g(x_{2,1},\dots x_{2,n})
    \]
    Хотим, запихнуть всё то, что содержит $x_i$ под знак квадрата.
    Тогда выражение выше равно следующему:
    \[
        a_{1,1}\left(x_1 + \frac{a_{1,2}}{a_{1,1}}x_2 + \dots + \frac{a_{1,n}}{a_{1,1}}x_n\right)^2 -
        \hat{g}(x_2,\dots, x_n) + g(x_2,\dots, x_n)
    .\]
    
    Убедимся, что матрица перехода в новой системе координат не вырожденная
     \[
         \begin{gathered}
             y_1 = x_1 + \frac{a_{1,2}}{a_{1,1}}x_2 + \dots + \frac{a_{1,n}}{a_{1,1}}x_n\\
             y_2 = x_2\\
             \vdots\\
             y_n = x_n
         \end{gathered}
    .\] 
    Тогда получаем следующую матрицу перехода:
    \[
    y = 
    \begin{pmatrix}
        1 & \frac{a_{1,2}}{a_{1,1}} & \dots & \frac{a_{1,n}}{a_{1,1}}\\
          & 1 & & &\\
          &  & \ddots &\vdots\\
          0 & & & 1\\
    \end{pmatrix}
    .\] 

    Но всё вышеперечисленное работает, когда $a_{1,1}\not= 0$.
    Давайте доразберём частные случаи:
    \begin{enumerate}
        \item
        Если $\exists a_{i,i} = 0$, тогда можно взять $y_1 = x_i, y_i = x_1$.
        \item
            Если $a_{i,i} = 0,\forall i$. Тогда допустим если $a_{1,2}\not=0$, то можно сделать замену:
        $2a_{1,2} x_1 x_2 \leftrightarrow
        \begin{pmatrix}
            0 & a_{1,2}\\
            a_{1, 2} & 0
        \end{pmatrix}$
        Тогда ответ можно будет восстановить следующим образом:
        $x_1 = y_1 + y_2, x_2 = y_1 - y_2$.
    \end{enumerate}
\end{proof}
Давайте поймём, каким преобразованиям мы подвергаем матрицу во время выполнения алгоритма из доказательсва
выше.
TODO(подобнее) работает очень похоже на алгоритм Гаусса. За одну итерацию мы делаем около $n$ элементарных
преобразований для строчек и для столбцов.
\begin{theorem}
    $q(x) = x^T Ax$. Пусть $d_i$~--- $i$ главный минор($d_0=1$). Тогда если $d_i \not= 0,\forall i$, на диагонали
    будут стоять следующие скаляры $\frac{d_i}{d_{i - 1}}$.
\end{theorem}
\begin{proof}
    Будет доказано на следующей лекции пользуясь теоремой с сегодняшней лекции.
\end{proof}
